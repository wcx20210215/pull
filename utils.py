"""
utils - æ•°æ®åˆ†ææ™ºèƒ½ä½“ä½¿ç”¨çš„å·¥å…·å‡½æ•°

Author: éª†æ˜Š
Version: 0.1
Date: 2025/6/25
"""
import json
import streamlit as st
import sqlite3
import hashlib
from datetime import datetime
from typing import List, Dict, Any
import time
import pandas as pd

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent

# è®°å¿†ç®¡ç†ç±»
class ConversationMemory:
    def __init__(self, db_path="conversation_memory.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºå¯¹è¯è®°å½•è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS conversations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT,
                question TEXT,
                answer TEXT,
                question_hash TEXT,
                data_hash TEXT,
                timestamp DATETIME,
                response_time REAL
            )
        """)
        
        # åˆ›å»ºå¿«é€Ÿå›ç­”ç¼“å­˜è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS quick_answers (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                question_hash TEXT UNIQUE,
                data_hash TEXT,
                question TEXT,
                answer TEXT,
                hit_count INTEGER DEFAULT 1,
                last_used DATETIME,
                created_at DATETIME
            )
        """)
        
        conn.commit()
        conn.close()
    
    def get_question_hash(self, question: str) -> str:
        """ç”Ÿæˆé—®é¢˜çš„å“ˆå¸Œå€¼"""
        return hashlib.md5(question.lower().strip().encode('utf-8')).hexdigest()
    
    def get_data_hash(self, df) -> str:
        """ç”Ÿæˆæ•°æ®çš„å“ˆå¸Œå€¼"""
        try:
            data_str = str(df.shape) + str(df.columns.tolist()) + str(df.dtypes.tolist())
            return hashlib.md5(data_str.encode('utf-8')).hexdigest()
        except:
            return "unknown"
    
    def add_conversation(self, session_id: str, question: str, answer: str, 
                        data_hash: str, response_time: float):
        """æ·»åŠ å¯¹è¯è®°å½•"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        question_hash = self.get_question_hash(question)
        
        cursor.execute("""
            INSERT INTO conversations 
            (session_id, question, answer, question_hash, data_hash, timestamp, response_time)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (session_id, question, answer, question_hash, data_hash, 
               datetime.now(), response_time))
        
        conn.commit()
        conn.close()
    
    def get_quick_answer(self, question: str, data_hash: str) -> Dict[str, Any]:
        """è·å–å¿«é€Ÿå›ç­”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        question_hash = self.get_question_hash(question)
        
        cursor.execute("""
            SELECT answer, hit_count FROM quick_answers 
            WHERE question_hash = ? AND data_hash = ?
        """, (question_hash, data_hash))
        
        result = cursor.fetchone()
        
        if result:
            # æ›´æ–°ä½¿ç”¨æ¬¡æ•°å’Œæœ€åä½¿ç”¨æ—¶é—´
            cursor.execute("""
                UPDATE quick_answers 
                SET hit_count = hit_count + 1, last_used = ?
                WHERE question_hash = ? AND data_hash = ?
            """, (datetime.now(), question_hash, data_hash))
            
            conn.commit()
            conn.close()
            
            return {
                "found": True,
                "answer": result[0],
                "hit_count": result[1] + 1
            }
        
        conn.close()
        return {"found": False}
    
    def save_quick_answer(self, question: str, answer: str, data_hash: str):
        """ä¿å­˜å¿«é€Ÿå›ç­”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        question_hash = self.get_question_hash(question)
        
        cursor.execute("""
            INSERT OR REPLACE INTO quick_answers 
            (question_hash, data_hash, question, answer, hit_count, last_used, created_at)
            VALUES (?, ?, ?, ?, 1, ?, ?)
        """, (question_hash, data_hash, question, answer, datetime.now(), datetime.now()))
        
        conn.commit()
        conn.close()
    
    def get_conversation_history(self, session_id: str, limit: int = 10) -> List[Dict]:
        """è·å–å¯¹è¯å†å²"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT question, answer, timestamp, response_time 
            FROM conversations 
            WHERE session_id = ? 
            ORDER BY timestamp DESC 
            LIMIT ?
        """, (session_id, limit))
        
        results = cursor.fetchall()
        conn.close()
        
        return [{
            "question": row[0],
            "answer": row[1],
            "timestamp": row[2],
            "response_time": row[3]
        } for row in reversed(results)]
    
    def get_popular_questions(self, data_hash: str, limit: int = 5) -> List[Dict]:
        """è·å–çƒ­é—¨é—®é¢˜"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT question, hit_count, last_used 
            FROM quick_answers 
            WHERE data_hash = ? 
            ORDER BY hit_count DESC 
            LIMIT ?
        """, (data_hash, limit))
        
        results = cursor.fetchall()
        conn.close()
        
        return [{
            "question": row[0],
            "hit_count": row[1],
            "last_used": row[2]
        } for row in results]

# æµå¼è¾“å‡ºå¤„ç†å™¨
class StreamingResponseHandler:
    def __init__(self):
        self.response_container = None
        self.current_text = ""
    
    def setup_container(self, container):
        """è®¾ç½®è¾“å‡ºå®¹å™¨"""
        self.response_container = container
        self.current_text = ""
    
    def stream_text(self, text: str, delay: float = 0.02):
        """æµå¼è¾“å‡ºæ–‡æœ¬"""
        if self.response_container:
            for char in text:
                self.current_text += char
                self.response_container.markdown(self.current_text + "â–Œ")
                time.sleep(delay)
            # ç§»é™¤å…‰æ ‡
            self.response_container.markdown(self.current_text)
    
    def stream_json_response(self, response_data: Dict, delay: float = 0.02):
        """æµå¼è¾“å‡ºJSONå“åº”"""
        if "answer" in response_data:
            self.stream_text(response_data["answer"], delay)
        return response_data

# å…¨å±€è®°å¿†ç®¡ç†å™¨å®ä¾‹
memory_manager = ConversationMemory()
streaming_handler = StreamingResponseHandler()

PROMPT_TEMPLATE = """æ•°æ®åˆ†æåŠ©æ‰‹ç™»åœºï¼ğŸš€æ•°æ®åˆ†æå°±åƒä¸€åœºå†’é™©ï¼Œè€Œæˆ‘å°±æ˜¯ä½ çš„å‘å¯¼ã€‚âœ¨ä¸‹é¢æ˜¯æˆ‘çš„é­”æ³•æŒ‡å—ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢æ•°æ®çš„å¥¥ç§˜ï¼š

1. **æ€è€ƒé˜¶æ®µ (Thought)** ï¼šé¦–å…ˆï¼Œæˆ‘ä¼šåƒä¾¦æ¢ä¸€æ ·åˆ†æä½ çš„è¯·æ±‚ç±»å‹ï¼ˆæ–‡å­—å›ç­”/è¡¨æ ¼/å›¾è¡¨ï¼‰ï¼Œå¹¶éªŒè¯æ•°æ®æ˜¯å¦åˆé€‚ã€‚ğŸ”

2. **è¡ŒåŠ¨é˜¶æ®µ (Action)** ï¼šæ ¹æ®åˆ†æç»“æœï¼Œæˆ‘ä¼šç”¨ä»¥ä¸‹é­”æ³•æ ¼å¼æ¥å›åº”ä½ ï¼šâœ¨
   - **çº¯æ–‡å­—å›ç­”**ï¼šï¼ˆç®€æ´æ˜äº†ï¼Œç»ä¸å•°å—¦ï¼‰
     {"answer": "ä¸è¶…è¿‡50ä¸ªå­—ç¬¦çš„æ˜ç¡®ç­”æ¡ˆ"}ğŸ‘

   - **è¡¨æ ¼æ•°æ®**ï¼šï¼ˆæ•´é½æ’åˆ—ï¼Œä¸€ç›®äº†ç„¶ï¼‰
     {"table":{"columns":["åˆ—å1", "åˆ—å2", ...], "data":[["ç¬¬ä¸€è¡Œå€¼1", "å€¼2", ...], ["ç¬¬äºŒè¡Œå€¼1", "å€¼2", ...]]}}ğŸ“Š

   - **æŸ±çŠ¶å›¾**ï¼šï¼ˆç›´è§‚å±•ç¤ºï¼Œé«˜ä½ç«‹ç°ï¼‰
     {"bar":{"columns": ["A", "B", "C", ...], "data":[35, 42, 29, ...]}}ğŸ“ˆ

   - **æŠ˜çº¿å›¾**ï¼šï¼ˆè¶‹åŠ¿å°½æ˜¾ï¼Œä¸€ç›®äº†ç„¶ï¼‰
     {"line":{"columns": ["A", "B", "C", ...], "data": [35, 42, 29, ...]}}ğŸ“ˆ

3. **æ ¼å¼æ ¡éªŒè¦æ±‚**ï¼šï¼ˆåˆ«æ‹…å¿ƒï¼Œæˆ‘ä¼šå°å¿ƒè°¨æ…ï¼Œç¡®ä¿ä¸‡æ— ä¸€å¤±ï¼‰ğŸ›¡ï¸
   - å­—ç¬¦ä¸²å€¼å¿…é¡»ä½¿ç”¨è‹±æ–‡åŒå¼•å·ï¼ˆåˆ«é—®æˆ‘ä¸ºä»€ä¹ˆï¼Œè¿™æ˜¯è§„çŸ©ï¼‰ğŸ¤”
   - æ•°å€¼ç±»å‹ä¸å¾—æ·»åŠ å¼•å·ï¼ˆæ•°å­—å°±æ˜¯æ•°å­—ï¼Œä¸éœ€è¦ä¼ªè£…ï¼‰ğŸš«
   - ç¡®ä¿æ•°ç»„é—­åˆæ— é—æ¼ï¼ˆæˆ‘å¯ä¸æƒ³æ¼æ‰ä»»ä½•é‡è¦ä¿¡æ¯ï¼‰âœ…

   é”™è¯¯æ¡ˆä¾‹ï¼šï¼ˆåé¢æ•™æï¼Œåƒä¸‡åˆ«å­¦ï¼‰ğŸ’©
   {'columns':['Product', 'Sales'], data:[[A001, 200]]}

   æ­£ç¡®æ¡ˆä¾‹ï¼šï¼ˆè¿™æ‰æ˜¯æ­£ç¡®çš„æ‰“å¼€æ–¹å¼ï¼‰ğŸ‘
   {"columns":["product", "sales"], "data":[["A001", 200]]}

æ³¨æ„ï¼šå“åº”æ•°æ®çš„"output"ä¸­ä¸è¦æœ‰æ¢è¡Œç¬¦ã€åˆ¶è¡¨ç¬¦ä»¥åŠå…¶ä»–æ ¼å¼ç¬¦å·ã€‚ï¼ˆä¿æŒæ•´æ´ï¼Œæ˜¯æˆ‘çš„åŸåˆ™ï¼‰ğŸ§¹

å½“å‰ç”¨æˆ·è¯·æ±‚å¦‚ä¸‹ï¼š\n"""


@st.cache_data(ttl=1800)  # ç¼“å­˜30åˆ†é’Ÿ
def cached_dataframe_analysis(df_hash, query_hash, query):
    """ç¼“å­˜æ•°æ®åˆ†æç»“æœ"""
    # å®é™…çš„åˆ†æé€»è¾‘ä¼šåœ¨dataframe_agentä¸­æ‰§è¡Œ
    return None

def get_enhanced_model():
    return ChatOpenAI(
        base_url='https://twapi.openai-hk.com/v1',
        api_key=st.secrets['API_KEY'],
        model="gpt-4o-mini",
        temperature=0,
        max_tokens=4096
    )

def dataframe_agent(df, query, use_cache=True,
                   session_id=None, enable_streaming=False, stream_container=None):
    """å¢å¼ºç‰ˆæ•°æ®åˆ†ææ™ºèƒ½ä½“ - æ”¯æŒè®°å¿†å’Œæµå¼è¾“å‡º"""
    
    start_time = time.time()
    
    # ç”Ÿæˆæ•°æ®å“ˆå¸Œ
    data_hash = memory_manager.get_data_hash(df)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¿«é€Ÿå›ç­”
    if use_cache:
        quick_answer = memory_manager.get_quick_answer(query, data_hash)
        if quick_answer["found"]:
            try:
                cached_result = json.loads(quick_answer["answer"])
                
                # å¦‚æœå¯ç”¨æµå¼è¾“å‡º
                if enable_streaming and stream_container:
                    streaming_handler.setup_container(stream_container)
                    return streaming_handler.stream_json_response(cached_result, delay=0.01)
                
                # è®°å½•å¿«é€Ÿå›ç­”çš„ä½¿ç”¨
                if session_id:
                    response_time = time.time() - start_time
                    memory_manager.add_conversation(
                        session_id, query, quick_answer["answer"], 
                        data_hash, response_time
                    )
                
                return cached_result
            except json.JSONDecodeError:
                # å¦‚æœç¼“å­˜çš„ç­”æ¡ˆä¸æ˜¯æœ‰æ•ˆJSONï¼Œç»§ç»­æ­£å¸¸å¤„ç†
                pass
    
    # ç”Ÿæˆç¼“å­˜é”®ï¼ˆä¿æŒåŸæœ‰ç¼“å­˜é€»è¾‘ï¼‰
    df_hash = hash(str(df.values.tobytes()) + str(df.columns.tolist()))
    query_hash = hash(query)
    
    # å°è¯•ä»åŸæœ‰ç¼“å­˜è·å–ç»“æœ
    if use_cache:
        try:
            cached_result = cached_dataframe_analysis(df_hash, query_hash, query)
            if cached_result:
                return cached_result
        except:
            pass
    
    # è·å–æ¨¡å‹
    model = get_enhanced_model()
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    try:
        agent = create_pandas_dataframe_agent(
            llm=model,
            df=df,
            verbose=True,
            allow_dangerous_code=True
        )
    except Exception as e:
        st.error(f"åˆ›å»ºæ™ºèƒ½ä½“æ—¶å‡ºé”™: {str(e)}")
        return {"answer": "æŠ±æ­‰ï¼ŒAIæ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"}

    # å¢å¼ºçš„æç¤ºè¯
    enhanced_prompt = PROMPT_TEMPLATE + f"""
    
    æ•°æ®é›†ä¿¡æ¯ï¼š
    - è¡Œæ•°ï¼š{len(df)}
    - åˆ—æ•°ï¼š{len(df.columns)}
    - åˆ—åï¼š{', '.join(df.columns.tolist())}
    - æ•°å€¼åˆ—ï¼š{', '.join(df.select_dtypes(include=['number']).columns.tolist())}
    - æ–‡æœ¬åˆ—ï¼š{', '.join(df.select_dtypes(include=['object']).columns.tolist())}
    
    ç”¨æˆ·é—®é¢˜ï¼š{query}
    
    è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„åˆ†æç»“æœã€‚
    """

    try:
        # æ‰§è¡Œåˆ†æ
        response = agent.invoke({"input": enhanced_prompt})
        result = json.loads(response["output"])
        
        # éªŒè¯ç»“æœæ ¼å¼
        if not isinstance(result, dict):
            raise ValueError("è¿”å›ç»“æœæ ¼å¼ä¸æ­£ç¡®")
        
        # è®¡ç®—å“åº”æ—¶é—´
        response_time = time.time() - start_time
        
        # ä¿å­˜åˆ°è®°å¿†ä¸­
        result_json = json.dumps(result, ensure_ascii=False)
        if session_id:
            memory_manager.add_conversation(
                session_id, query, result_json, data_hash, response_time
            )
        
        # ä¿å­˜ä¸ºå¿«é€Ÿå›ç­”ï¼ˆå¦‚æœç»“æœæœ‰æ•ˆï¼‰
        if "answer" in result or "table" in result or "bar" in result or "line" in result:
            memory_manager.save_quick_answer(query, result_json, data_hash)
        
        # å¦‚æœå¯ç”¨æµå¼è¾“å‡º
        if enable_streaming and stream_container:
            streaming_handler.setup_container(stream_container)
            return streaming_handler.stream_json_response(result)
            
        return result
        
    except json.JSONDecodeError as e:
        print(f"JSONè§£æé”™è¯¯: {e}")
        error_result = {"answer": "åˆ†æç»“æœæ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°å°è¯•"}
        
        # è®°å½•é”™è¯¯åˆ°å¯¹è¯å†å²
        if session_id:
            response_time = time.time() - start_time
            memory_manager.add_conversation(
                session_id, query, json.dumps(error_result, ensure_ascii=False), 
                data_hash, response_time
            )
        
        return error_result
        
    except Exception as err:
        print(f"åˆ†æé”™è¯¯: {err}")
        error_messages = [
            "æš‚æ—¶æ— æ³•æä¾›åˆ†æç»“æœï¼Œè¯·ç¨åé‡è¯•ï¼",
            "æ•°æ®åˆ†æé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–ç®€åŒ–é—®é¢˜",
            "AIåˆ†æè¶…æ—¶ï¼Œè¯·å°è¯•æ›´ç®€å•çš„é—®é¢˜",
            "åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚"
        ]
        import random
        error_result = {"answer": random.choice(error_messages)}
        
        # è®°å½•é”™è¯¯åˆ°å¯¹è¯å†å²
        if session_id:
            response_time = time.time() - start_time
            memory_manager.add_conversation(
                session_id, query, json.dumps(error_result, ensure_ascii=False), 
                data_hash, response_time
            )
        
        return error_result

def multi_model_analysis(df, query):
    """æ•°æ®åˆ†æ - ä½¿ç”¨å•ä¸€æ¨¡å‹"""
    try:
        result = dataframe_agent(df, query, use_cache=False)
        return result
    except Exception as e:
        print(f"æ¨¡å‹åˆ†æå¤±è´¥: {e}")
        return {"answer": "åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–é—®é¢˜"}

# è®°å¿†ç®¡ç†è¾…åŠ©å‡½æ•°
def get_session_id():
    """è·å–æˆ–åˆ›å»ºä¼šè¯ID"""
    if "session_id" not in st.session_state:
        st.session_state.session_id = f"session_{int(time.time())}_{hash(str(time.time()))}"
    return st.session_state.session_id

def display_conversation_history(df, limit=5):
    """æ˜¾ç¤ºå¯¹è¯å†å²"""
    session_id = get_session_id()
    data_hash = memory_manager.get_data_hash(df)
    
    history = memory_manager.get_conversation_history(session_id, limit)
    
    if history:
        for i, conv in enumerate(history):
            question_preview = conv['question'][:50] if len(conv['question']) > 50 else conv['question']
            st.markdown(f"**ğŸ’¬ é—®é¢˜ {i+1}:** {question_preview}...")
            
            with st.container():
                st.markdown(f"**å®Œæ•´é—®é¢˜:** {conv['question']}")
                try:
                    answer_data = json.loads(conv['answer'])
                    if "answer" in answer_data:
                        st.markdown(f"**å›ç­”:** {answer_data['answer']}")
                    if "table" in answer_data:
                        st.markdown("**æ•°æ®è¡¨æ ¼:**")
                        result_df = pd.DataFrame(answer_data["table"]["data"],
                                               columns=answer_data["table"]["columns"])
                        st.dataframe(result_df, use_container_width=True)
                except:
                    st.markdown(f"**å›ç­”:** {conv['answer']}")
                
                st.caption(f"â±ï¸ å“åº”æ—¶é—´: {conv['response_time']:.2f}ç§’ | ğŸ• æ—¶é—´: {conv['timestamp']}")
                st.divider()
    else:
        st.info("æš‚æ— å¯¹è¯å†å²")

def display_popular_questions(df, limit=5):
    """æ˜¾ç¤ºçƒ­é—¨é—®é¢˜"""
    data_hash = memory_manager.get_data_hash(df)
    popular = memory_manager.get_popular_questions(data_hash, limit)
    
    if popular:
        for i, item in enumerate(popular):
            col1, col2 = st.columns([4, 1])
            with col1:
                if st.button(f"ğŸ“ {item['question']}", key=f"popular_{i}"):
                    st.session_state.selected_question = item['question']
                    st.rerun()
            with col2:
                st.caption(f"ğŸ”¥ {item['hit_count']}æ¬¡")
    else:
        st.info("æš‚æ— çƒ­é—¨é—®é¢˜")

def get_memory_stats(df):
    """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
    session_id = get_session_id()
    data_hash = memory_manager.get_data_hash(df)
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    conn = sqlite3.connect(memory_manager.db_path)
    cursor = conn.cursor()
    
    # å½“å‰ä¼šè¯é—®é¢˜æ•°
    cursor.execute(
        "SELECT COUNT(*) FROM conversations WHERE session_id = ?", 
        (session_id,)
    )
    session_count = cursor.fetchone()[0]
    
    # å½“å‰æ•°æ®é›†çš„å¿«é€Ÿå›ç­”æ•°
    cursor.execute(
        "SELECT COUNT(*) FROM quick_answers WHERE data_hash = ?", 
        (data_hash,)
    )
    quick_answers_count = cursor.fetchone()[0]
    
    # æ€»å¯¹è¯æ•°
    cursor.execute("SELECT COUNT(*) FROM conversations")
    total_conversations = cursor.fetchone()[0]
    
    # å¹³å‡å“åº”æ—¶é—´
    cursor.execute(
        "SELECT AVG(response_time) FROM conversations WHERE data_hash = ?", 
        (data_hash,)
    )
    avg_response_time = cursor.fetchone()[0] or 0
    
    conn.close()
    
    return {
        "session_count": session_count,
        "quick_answers_count": quick_answers_count,
        "total_conversations": total_conversations,
        "avg_response_time": avg_response_time
    }

def clear_session_memory(session_id):
    """æ¸…é™¤æŒ‡å®šä¼šè¯çš„è®°å¿†"""
    conn = sqlite3.connect(memory_manager.db_path)
    cursor = conn.cursor()
    
    cursor.execute(
        "DELETE FROM conversations WHERE session_id = ?", 
        (session_id,)
    )
    
    deleted_count = cursor.rowcount
    conn.commit()
    conn.close()
    
    return deleted_count

def clear_all_memory():
    """æ¸…é™¤æ‰€æœ‰è®°å¿†æ•°æ®"""
    conn = sqlite3.connect(memory_manager.db_path)
    cursor = conn.cursor()
    
    cursor.execute("DELETE FROM conversations")
    cursor.execute("DELETE FROM quick_answers")
    
    conn.commit()
    conn.close()
    
    return True