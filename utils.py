"""
utils - æ•°æ®åˆ†ææ™ºèƒ½ä½“ä½¿ç”¨çš„å·¥å…·å‡½æ•°

Author: éª†æ˜Š
Version: 0.1
Date: 2025/6/25
"""
import json
import streamlit as st
import sqlite3
import hashlib
import time
from datetime import datetime
from typing import List, Dict, Any
import sys

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent

PROMPT_TEMPLATE = """æ•°æ®åˆ†æåŠ©æ‰‹ç™»åœºï¼ğŸš€æ•°æ®åˆ†æå°±åƒä¸€åœºå†’é™©ï¼Œè€Œæˆ‘å°±æ˜¯ä½ çš„å‘å¯¼ã€‚âœ¨ä¸‹é¢æ˜¯æˆ‘çš„é­”æ³•æŒ‡å—ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢æ•°æ®çš„å¥¥ç§˜ï¼š

1. **æ€è€ƒé˜¶æ®µ (Thought)** ï¼šé¦–å…ˆï¼Œæˆ‘ä¼šåƒä¾¦æ¢ä¸€æ ·åˆ†æä½ çš„è¯·æ±‚ç±»å‹ï¼ˆæ–‡å­—å›ç­”/è¡¨æ ¼/å›¾è¡¨ï¼‰ï¼Œå¹¶éªŒè¯æ•°æ®æ˜¯å¦åˆé€‚ã€‚ğŸ”

2. **è¡ŒåŠ¨é˜¶æ®µ (Action)** ï¼šæ ¹æ®åˆ†æç»“æœï¼Œæˆ‘ä¼šç”¨ä»¥ä¸‹é­”æ³•æ ¼å¼æ¥å›åº”ä½ ï¼šâœ¨
   - **çº¯æ–‡å­—å›ç­”**ï¼šï¼ˆç®€æ´æ˜äº†ï¼Œç»ä¸å•°å—¦ï¼‰
     {"answer": "ä¸è¶…è¿‡200ä¸ªå­—ç¬¦çš„æ˜ç¡®ç­”æ¡ˆ"}ğŸ‘

   - **è¡¨æ ¼æ•°æ®**ï¼šï¼ˆæ•´é½æ’åˆ—ï¼Œä¸€ç›®äº†ç„¶ï¼‰
     {"table":{"columns":["åˆ—å1", "åˆ—å2", ...], "data":[["ç¬¬ä¸€è¡Œå€¼1", "å€¼2", ...], ["ç¬¬äºŒè¡Œå€¼1", "å€¼2", ...]]}}ğŸ“Š

   - **æŸ±çŠ¶å›¾**ï¼šï¼ˆç›´è§‚å±•ç¤ºï¼Œé«˜ä½ç«‹ç°ï¼‰
     {"bar":{"columns": ["ç±»åˆ«A", "ç±»åˆ«B", "ç±»åˆ«C"], "data":[35, 42, 29]}}ğŸ“ˆ

   - **æŠ˜çº¿å›¾**ï¼šï¼ˆè¶‹åŠ¿å°½æ˜¾ï¼Œä¸€ç›®äº†ç„¶ï¼‰
     {"line":{"columns": ["æ—¶é—´1", "æ—¶é—´2", "æ—¶é—´3"], "data": [35, 42, 29]}}ğŸ“ˆ

   - **é¥¼å›¾**ï¼šï¼ˆå æ¯”æ¸…æ™°ï¼Œä¸€ç›®äº†ç„¶ï¼‰
     {"pie":{"columns": ["éƒ¨åˆ†A", "éƒ¨åˆ†B", "éƒ¨åˆ†C"], "data": [35, 42, 29]}}ğŸ¥§

3. **é‡è¦æ ¼å¼è¦æ±‚**ï¼šğŸ›¡ï¸
   - å¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
   - å­—ç¬¦ä¸²å€¼å¿…é¡»ä½¿ç”¨è‹±æ–‡åŒå¼•å·
   - æ•°å€¼ç±»å‹ä¸è¦æ·»åŠ å¼•å·
   - å›¾è¡¨æ•°æ®å¿…é¡»åŒ…å«"columns"å’Œ"data"ä¸¤ä¸ªå­—æ®µ
   - columnsæ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼Œdataæ˜¯æ•°å€¼æ•°ç»„
   - columnså’Œdataçš„é•¿åº¦å¿…é¡»ç›¸ç­‰
   - ä¸è¦åœ¨JSONä¸­æ·»åŠ æ³¨é‡Šæˆ–é¢å¤–çš„æ ¼å¼ç¬¦å·

   **æ­£ç¡®çš„å›¾è¡¨æ ¼å¼ç¤ºä¾‹ï¼š**
   {"bar":{"columns":["äº§å“A", "äº§å“B", "äº§å“C"], "data":[100, 200, 150]}}
   {"line":{"columns":["1æœˆ", "2æœˆ", "3æœˆ"], "data":[50, 75, 90]}}
   {"pie":{"columns":["ç±»å‹1", "ç±»å‹2", "ç±»å‹3"], "data":[30, 45, 25]}}

   **é”™è¯¯æ ¼å¼ï¼ˆä¸è¦è¿™æ ·åšï¼‰ï¼š**
   {bar: {x: [A, B], y: [1, 2]}}  // ç¼ºå°‘å¼•å·ï¼Œå­—æ®µåé”™è¯¯
   {"bar": {"data": [1, 2]}}      // ç¼ºå°‘columnså­—æ®µ

4. **æ•°æ®éªŒè¯**ï¼šç¡®ä¿è¿”å›çš„æ•°æ®æ ¼å¼å®Œå…¨æ­£ç¡®ï¼Œç‰¹åˆ«æ˜¯å›¾è¡¨å¯è§†åŒ–è¯·æ±‚æ—¶ã€‚

å½“å‰ç”¨æˆ·è¯·æ±‚å¦‚ä¸‹ï¼š\n"""


class ChatMemory:
    """å¯¹è¯è®°å¿†ç®¡ç†ç±»"""
    
    def __init__(self, db_path="chat_memory.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºå¯¹è¯å†å²è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS chat_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                user_message TEXT NOT NULL,
                ai_response TEXT NOT NULL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                data_hash TEXT
            )
        """)
        
        # åˆ›å»ºç¼“å­˜è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS response_cache (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                query_hash TEXT UNIQUE NOT NULL,
                data_hash TEXT NOT NULL,
                query TEXT NOT NULL,
                response TEXT NOT NULL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.commit()
        conn.close()
    
    def get_session_id(self):
        """è·å–æˆ–åˆ›å»ºä¼šè¯ID"""
        if 'chat_session_id' not in st.session_state:
            st.session_state.chat_session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        return st.session_state.chat_session_id
    
    def generate_hash(self, content: str) -> str:
        """ç”Ÿæˆå†…å®¹å“ˆå¸Œ"""
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def add_message(self, user_message: str, ai_response: str, data_hash: str = None):
        """æ·»åŠ å¯¹è¯æ¶ˆæ¯åˆ°è®°å¿†ä¸­"""
        session_id = self.get_session_id()
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO chat_history (session_id, user_message, ai_response, data_hash)
            VALUES (?, ?, ?, ?)
        """, (session_id, user_message, ai_response, data_hash))
        
        conn.commit()
        conn.close()
    
    def get_chat_history(self, data_hash: str = None, limit: int = 10) -> List[tuple]:
        """è·å–å¯¹è¯å†å²"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if data_hash:
            cursor.execute("""
                SELECT user_message, ai_response, timestamp
                FROM chat_history
                WHERE data_hash = ?
                ORDER BY timestamp DESC
                LIMIT ?
            """, (data_hash, limit))
        else:
            session_id = self.get_session_id()
            cursor.execute("""
                SELECT user_message, ai_response, timestamp
                FROM chat_history
                WHERE session_id = ?
                ORDER BY timestamp DESC
                LIMIT ?
            """, (session_id, limit))
        
        results = cursor.fetchall()
        conn.close()
        
        # åè½¬é¡ºåºï¼Œä½¿æœ€æ–°çš„åœ¨æœ€å
        return list(reversed(results))
    
    def get_cached_response(self, query: str, data_hash: str) -> str:
        """è·å–ç¼“å­˜çš„å“åº”"""
        query_hash = self.generate_hash(query + data_hash)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT response FROM response_cache
            WHERE query_hash = ? AND data_hash = ?
            AND datetime(timestamp) > datetime('now', '-1 hour')
        """, (query_hash, data_hash))
        
        result = cursor.fetchone()
        conn.close()
        
        return result[0] if result else None
    
    def cache_response(self, query: str, response: str, data_hash: str):
        """ç¼“å­˜å“åº”"""
        query_hash = self.generate_hash(query + data_hash)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ä½¿ç”¨ INSERT OR REPLACE æ¥æ›´æ–°ç¼“å­˜
        cursor.execute("""
            INSERT OR REPLACE INTO response_cache (query_hash, data_hash, query, response)
            VALUES (?, ?, ?, ?)
        """, (query_hash, data_hash, query, response))
        
        conn.commit()
        conn.close()
    
    def clear_session_history(self, data_hash: str = None):
        """æ¸…é™¤ä¼šè¯å†å²"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if data_hash:
            cursor.execute("DELETE FROM chat_history WHERE data_hash = ?", (data_hash,))
        else:
            session_id = self.get_session_id()
            cursor.execute("DELETE FROM chat_history WHERE session_id = ?", (session_id,))
            # é‡æ–°ç”Ÿæˆä¼šè¯ID
            if 'chat_session_id' in st.session_state:
                del st.session_state.chat_session_id
        
        conn.commit()
        conn.close()

# å…¨å±€å®ä¾‹
chat_memory = ChatMemory()

def get_conversation_history(df, limit=10):
    """è·å–æŒ‡å®šæ•°æ®é›†çš„å¯¹è¯å†å²"""
    df_hash = chat_memory.generate_hash(str(df.values.tobytes()) + str(df.columns.tolist()))
    return chat_memory.get_chat_history(df_hash, limit)

def clear_conversation_history(df):
    """æ¸…é™¤æŒ‡å®šæ•°æ®é›†çš„å¯¹è¯å†å²"""
    df_hash = chat_memory.generate_hash(str(df.values.tobytes()) + str(df.columns.tolist()))
    chat_memory.clear_session_history(df_hash)
    return True

@st.cache_data(ttl=1800)  # ç¼“å­˜30åˆ†é’Ÿ
def cached_dataframe_analysis(df_hash, query_hash, query):
    """ç¼“å­˜æ•°æ®åˆ†æç»“æœ"""
    # å®é™…çš„åˆ†æé€»è¾‘ä¼šåœ¨dataframe_agentä¸­æ‰§è¡Œ
    return None

def get_enhanced_model(model_choice="gpt-4o-mini"):
    """è·å–å¢å¼ºçš„AIæ¨¡å‹"""
    model_configs = {
        "gpt-4o": {
            "model": "gpt-4o",
            "temperature": 0.1,
            "max_tokens": 8192
        },
        "gpt-4o-mini": {
            "model": "gpt-4o-mini", 
            "temperature": 0,
            "max_tokens": 4096
        },
        "gpt-4-turbo": {
            "model": "gpt-4-turbo-preview",
            "temperature": 0.2,
            "max_tokens": 8192
        }
    }
    
    config = model_configs.get(model_choice, model_configs["gpt-4o-mini"])
    
    return ChatOpenAI(
        base_url='https://twapi.openai-hk.com/v1',
        api_key=st.secrets['API_KEY'],
        **config
    )

def dataframe_agent_streaming(df, query, model_choice="gpt-4o-mini", use_cache=True, stream_container=None):
    """æµå¼æ•°æ®åˆ†ææ™ºèƒ½ä½“"""
    
    # ç”Ÿæˆæ•°æ®å“ˆå¸Œ
    df_hash = chat_memory.generate_hash(str(df.values.tobytes()) + str(df.columns.tolist()))
    
    # æ£€æŸ¥ç¼“å­˜
    if use_cache:
        cached_result = chat_memory.get_cached_response(query, df_hash)
        if cached_result:
            if stream_container:
                stream_container.success("âœ… ä»ç¼“å­˜è·å–ç»“æœ")
            try:
                return json.loads(cached_result)
            except:
                pass
    
    # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†ä¸­ï¼ˆä¸´æ—¶å­˜å‚¨ï¼‰
    if 'temp_user_message' not in st.session_state:
        st.session_state.temp_user_message = query
    
    try:
        # è·å–æ¨¡å‹
        model = get_enhanced_model(model_choice)
        
        # æ„å»ºå¢å¼ºæç¤º
        dataset_info = f"æ•°æ®é›†ä¿¡æ¯ï¼š{len(df)}è¡Œ x {len(df.columns)}åˆ—\nåˆ—åï¼š{', '.join(df.columns[:10])}{'...' if len(df.columns) > 10 else ''}"
        enhanced_prompt = f"{PROMPT_TEMPLATE}\n\n{dataset_info}\n\nç”¨æˆ·é—®é¢˜ï¼š{query}"
        
        # åˆ›å»ºä»£ç†
        agent = create_pandas_dataframe_agent(
            llm=model,
            df=df,
            handle_parsing_errors=True,
            max_iterations=32,
            allow_dangerous_code=True,
            verbose=True,
            return_intermediate_steps=False
        )
        
        # æµå¼æ‰§è¡Œåˆ†æ
        if stream_container:
            with stream_container:
                st.write("ğŸ¤” AIæ­£åœ¨åˆ†æä¸­...")
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # æ¨¡æ‹Ÿæµå¼å¤„ç†
                import time
                for i in range(100):
                    progress_bar.progress(i + 1)
                    if i < 30:
                        status_text.text("ğŸ“Š æ­£åœ¨ç†è§£æ•°æ®ç»“æ„...")
                    elif i < 60:
                        status_text.text("ğŸ” æ­£åœ¨åˆ†ææŸ¥è¯¢éœ€æ±‚...")
                    elif i < 90:
                        status_text.text("âš¡ æ­£åœ¨ç”Ÿæˆåˆ†æç»“æœ...")
                    else:
                        status_text.text("âœ¨ å³å°†å®Œæˆ...")
                    time.sleep(0.02)
                
                progress_bar.empty()
                status_text.empty()
        
        # æ‰§è¡Œåˆ†æ
        result = agent.invoke({"input": enhanced_prompt})
        
        # å¤„ç†ç»“æœ
        if isinstance(result, dict) and "output" in result:
            output = result["output"]
        else:
            output = str(result)
        
        # å°è¯•è§£æJSON
        try:
            parsed_result = json.loads(output)
            
            # éªŒè¯å’Œä¿®å¤å›¾è¡¨æ•°æ®æ ¼å¼
            for chart_type in ["bar", "line", "pie"]:
                if chart_type in parsed_result:
                    chart_data = parsed_result[chart_type]
                    
                    # ç¡®ä¿å›¾è¡¨æ•°æ®æœ‰æ­£ç¡®çš„æ ¼å¼
                    if isinstance(chart_data, dict):
                        if "columns" not in chart_data or "data" not in chart_data:
                            # å°è¯•ä»å…¶ä»–å¯èƒ½çš„å­—æ®µåä¸­æå–æ•°æ®
                            if "x" in chart_data and "y" in chart_data:
                                chart_data["columns"] = chart_data.pop("x")
                                chart_data["data"] = chart_data.pop("y")
                            elif "labels" in chart_data and "values" in chart_data:
                                chart_data["columns"] = chart_data.pop("labels")
                                chart_data["data"] = chart_data.pop("values")
                            elif "categories" in chart_data and "values" in chart_data:
                                chart_data["columns"] = chart_data.pop("categories")
                                chart_data["data"] = chart_data.pop("values")
                        
                        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                        if "columns" in chart_data and "data" in chart_data:
                            if not isinstance(chart_data["columns"], list):
                                chart_data["columns"] = list(chart_data["columns"])
                            if not isinstance(chart_data["data"], list):
                                chart_data["data"] = list(chart_data["data"])
                    else:
                        # å¦‚æœchart_dataä¸æ˜¯å­—å…¸ï¼Œå°è¯•é‡æ–°æ„é€ 
                        parsed_result[chart_type] = {"answer": f"å›¾è¡¨æ•°æ®æ ¼å¼é”™è¯¯: {str(chart_data)}"}
            
            # éªŒè¯è¡¨æ ¼æ•°æ®æ ¼å¼
            if "table" in parsed_result:
                table_data = parsed_result["table"]
                if isinstance(table_data, dict):
                    if "columns" not in table_data or "data" not in table_data:
                        # å°è¯•ä¿®å¤è¡¨æ ¼æ ¼å¼
                        if "headers" in table_data and "rows" in table_data:
                            table_data["columns"] = table_data.pop("headers")
                            table_data["data"] = table_data.pop("rows")
                        elif "cols" in table_data and "rows" in table_data:
                            table_data["columns"] = table_data.pop("cols")
                            table_data["data"] = table_data.pop("rows")
                        
                    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                    if "columns" in table_data and "data" in table_data:
                        if not isinstance(table_data["columns"], list):
                            table_data["columns"] = list(table_data["columns"])
                        if not isinstance(table_data["data"], list):
                            table_data["data"] = list(table_data["data"])
                            
        except json.JSONDecodeError as e:
            # å¦‚æœä¸æ˜¯JSONï¼Œå°è¯•æå–å¯èƒ½çš„JSONéƒ¨åˆ†
            import re
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            json_matches = re.findall(json_pattern, output)
            
            if json_matches:
                try:
                    # å°è¯•è§£ææ‰¾åˆ°çš„JSON
                    parsed_result = json.loads(json_matches[-1])  # ä½¿ç”¨æœ€åä¸€ä¸ªåŒ¹é…çš„JSON
                except:
                    parsed_result = {"answer": output}
            else:
                # å¦‚æœå®Œå…¨ä¸æ˜¯JSONï¼ŒåŒ…è£…ä¸ºansweræ ¼å¼
                parsed_result = {"answer": output}
        except Exception as e:
            parsed_result = {"answer": f"ç»“æœè§£æé”™è¯¯: {str(e)}\nåŸå§‹è¾“å‡º: {output}"}
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        if 'debug_mode' in st.session_state and st.session_state.debug_mode:
            parsed_result['_debug_info'] = {
                'raw_output': output[:500] + '...' if len(output) > 500 else output,
                'output_type': type(output).__name__,
                'output_length': len(output)
            }
        
        # ç¼“å­˜ç»“æœ
        if use_cache:
            chat_memory.cache_response(query, json.dumps(parsed_result, ensure_ascii=False), df_hash)
        
        # å°†å®Œæ•´å¯¹è¯æ·»åŠ åˆ°è®°å¿†ä¸­
        chat_memory.add_message(
            st.session_state.get('temp_user_message', query),
            json.dumps(parsed_result, ensure_ascii=False),
            df_hash
        )
        
        # æ¸…ç†ä¸´æ—¶çŠ¶æ€
        if 'temp_user_message' in st.session_state:
            del st.session_state.temp_user_message
        
        return parsed_result
        
    except Exception as e:
        error_msg = f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
        if stream_container:
            stream_container.error(error_msg)
        
        # è®°å½•é”™è¯¯åˆ°å¯¹è¯å†å²
        chat_memory.add_message(
            st.session_state.get('temp_user_message', query),
            error_msg,
            df_hash
        )
        
        return {"answer": error_msg}

def dataframe_agent(df, query, model_choice="gpt-4o-mini", use_cache=True):
    """å¢å¼ºç‰ˆæ•°æ®åˆ†ææ™ºèƒ½ä½“"""
    
    # ç”Ÿæˆç¼“å­˜é”®
    df_hash = hash(str(df.values.tobytes()) + str(df.columns.tolist()))
    query_hash = hash(query)
    
    # å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
    if use_cache:
        try:
            cached_result = cached_dataframe_analysis(df_hash, query_hash, query)
            if cached_result:
                return cached_result
        except:
            pass
    
    # é€‰æ‹©æ¨¡å‹
    model = get_enhanced_model(model_choice)
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    try:
        agent = create_pandas_dataframe_agent(
            llm=model,
            df=df,
            verbose=True,
            allow_dangerous_code=True
        )
    except Exception as e:
        st.error(f"åˆ›å»ºæ™ºèƒ½ä½“æ—¶å‡ºé”™: {str(e)}")
        return {"answer": "æŠ±æ­‰ï¼ŒAIæ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"}

    # å¢å¼ºçš„æç¤ºè¯
    enhanced_prompt = PROMPT_TEMPLATE + f"""
    
    æ•°æ®é›†ä¿¡æ¯ï¼š
    - è¡Œæ•°ï¼š{len(df)}
    - åˆ—æ•°ï¼š{len(df.columns)}
    - åˆ—åï¼š{', '.join(df.columns.tolist())}
    - æ•°å€¼åˆ—ï¼š{', '.join(df.select_dtypes(include=['number']).columns.tolist())}
    - æ–‡æœ¬åˆ—ï¼š{', '.join(df.select_dtypes(include=['object']).columns.tolist())}
    
    ç”¨æˆ·é—®é¢˜ï¼š{query}
    
    è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„åˆ†æç»“æœã€‚
    """

    try:
        # æ‰§è¡Œåˆ†æ
        response = agent.invoke({"input": enhanced_prompt})
        result = json.loads(response["output"])
        
        # éªŒè¯ç»“æœæ ¼å¼
        if not isinstance(result, dict):
            raise ValueError("è¿”å›ç»“æœæ ¼å¼ä¸æ­£ç¡®")
            
        return result
        
    except json.JSONDecodeError as e:
        print(f"JSONè§£æé”™è¯¯: {e}")
        return {"answer": "åˆ†æç»“æœæ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°å°è¯•"}
    except Exception as err:
        print(f"åˆ†æé”™è¯¯: {err}")
        error_messages = [
            "æš‚æ—¶æ— æ³•æä¾›åˆ†æç»“æœï¼Œè¯·ç¨åé‡è¯•ï¼",
            "æ•°æ®åˆ†æé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–ç®€åŒ–é—®é¢˜",
            "AIåˆ†æè¶…æ—¶ï¼Œè¯·å°è¯•æ›´ç®€å•çš„é—®é¢˜",
            "åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚"
        ]
        import random
        return {"answer": random.choice(error_messages)}

def multi_model_analysis(df, query, models=["gpt-4o", "gpt-4o-mini"]):
    """å¤šæ¨¡å‹é›†æˆåˆ†æ"""
    results = []
    
    for model in models:
        try:
            result = dataframe_agent(df, query, model_choice=model, use_cache=False)
            results.append({"model": model, "result": result})
        except Exception as e:
            print(f"æ¨¡å‹ {model} åˆ†æå¤±è´¥: {e}")
            continue
    
    if not results:
        return {"answer": "æ‰€æœ‰æ¨¡å‹åˆ†æéƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–é—®é¢˜"}
    
    # ç®€å•çš„ç»“æœåˆå¹¶ç­–ç•¥ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›ï¼‰
    if len(results) == 1:
        return results[0]["result"]
    
    # å¦‚æœæœ‰å¤šä¸ªç»“æœï¼Œè¿”å›ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœï¼Œå¹¶æ·»åŠ å¤‡æ³¨
    primary_result = results[0]["result"]
    if "answer" in primary_result:
        primary_result["answer"] += f" (åŸºäº{len(results)}ä¸ªæ¨¡å‹çš„åˆ†æç»“æœ)"
    
    return primary_result