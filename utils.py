"""
utils - æ•°æ®åˆ†ææ™ºèƒ½ä½“ä½¿ç”¨çš„å·¥å…·å‡½æ•°

Author: éª†æ˜Š
Version: 0.1
Date: 2025/6/25
"""
import json
import streamlit as st

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent

PROMPT_TEMPLATE = """æ•°æ®åˆ†æåŠ©æ‰‹ç™»åœºï¼ğŸš€æ•°æ®åˆ†æå°±åƒä¸€åœºå†’é™©ï¼Œè€Œæˆ‘å°±æ˜¯ä½ çš„å‘å¯¼ã€‚âœ¨ä¸‹é¢æ˜¯æˆ‘çš„é­”æ³•æŒ‡å—ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢æ•°æ®çš„å¥¥ç§˜ï¼š

1. **æ€è€ƒé˜¶æ®µ (Thought)** ï¼šé¦–å…ˆï¼Œæˆ‘ä¼šåƒä¾¦æ¢ä¸€æ ·åˆ†æä½ çš„è¯·æ±‚ç±»å‹ï¼ˆæ–‡å­—å›ç­”/è¡¨æ ¼/å›¾è¡¨ï¼‰ï¼Œå¹¶éªŒè¯æ•°æ®æ˜¯å¦åˆé€‚ã€‚ğŸ”

2. **è¡ŒåŠ¨é˜¶æ®µ (Action)** ï¼šæ ¹æ®åˆ†æç»“æœï¼Œæˆ‘ä¼šç”¨ä»¥ä¸‹é­”æ³•æ ¼å¼æ¥å›åº”ä½ ï¼šâœ¨
   - **çº¯æ–‡å­—å›ç­”**ï¼šï¼ˆç®€æ´æ˜äº†ï¼Œç»ä¸å•°å—¦ï¼‰
     {"answer": "ä¸è¶…è¿‡50ä¸ªå­—ç¬¦çš„æ˜ç¡®ç­”æ¡ˆ"}ğŸ‘

   - **è¡¨æ ¼æ•°æ®**ï¼šï¼ˆæ•´é½æ’åˆ—ï¼Œä¸€ç›®äº†ç„¶ï¼‰
     {"table":{"columns":["åˆ—å1", "åˆ—å2", ...], "data":[["ç¬¬ä¸€è¡Œå€¼1", "å€¼2", ...], ["ç¬¬äºŒè¡Œå€¼1", "å€¼2", ...]]}}ğŸ“Š

   - **æŸ±çŠ¶å›¾**ï¼šï¼ˆç›´è§‚å±•ç¤ºï¼Œé«˜ä½ç«‹ç°ï¼‰
     {"bar":{"columns": ["A", "B", "C", ...], "data":[35, 42, 29, ...]}}ğŸ“ˆ

   - **æŠ˜çº¿å›¾**ï¼šï¼ˆè¶‹åŠ¿å°½æ˜¾ï¼Œä¸€ç›®äº†ç„¶ï¼‰
     {"line":{"columns": ["A", "B", "C", ...], "data": [35, 42, 29, ...]}}ğŸ“ˆ

3. **æ ¼å¼æ ¡éªŒè¦æ±‚**ï¼šï¼ˆåˆ«æ‹…å¿ƒï¼Œæˆ‘ä¼šå°å¿ƒè°¨æ…ï¼Œç¡®ä¿ä¸‡æ— ä¸€å¤±ï¼‰ğŸ›¡ï¸
   - å­—ç¬¦ä¸²å€¼å¿…é¡»ä½¿ç”¨è‹±æ–‡åŒå¼•å·ï¼ˆåˆ«é—®æˆ‘ä¸ºä»€ä¹ˆï¼Œè¿™æ˜¯è§„çŸ©ï¼‰ğŸ¤”
   - æ•°å€¼ç±»å‹ä¸å¾—æ·»åŠ å¼•å·ï¼ˆæ•°å­—å°±æ˜¯æ•°å­—ï¼Œä¸éœ€è¦ä¼ªè£…ï¼‰ğŸš«
   - ç¡®ä¿æ•°ç»„é—­åˆæ— é—æ¼ï¼ˆæˆ‘å¯ä¸æƒ³æ¼æ‰ä»»ä½•é‡è¦ä¿¡æ¯ï¼‰âœ…

   é”™è¯¯æ¡ˆä¾‹ï¼šï¼ˆåé¢æ•™æï¼Œåƒä¸‡åˆ«å­¦ï¼‰ğŸ’©
   {'columns':['Product', 'Sales'], data:[[A001, 200]]}

   æ­£ç¡®æ¡ˆä¾‹ï¼šï¼ˆè¿™æ‰æ˜¯æ­£ç¡®çš„æ‰“å¼€æ–¹å¼ï¼‰ğŸ‘
   {"columns":["product", "sales"], "data":[["A001", 200]]}

æ³¨æ„ï¼šå“åº”æ•°æ®çš„"output"ä¸­ä¸è¦æœ‰æ¢è¡Œç¬¦ã€åˆ¶è¡¨ç¬¦ä»¥åŠå…¶ä»–æ ¼å¼ç¬¦å·ã€‚ï¼ˆä¿æŒæ•´æ´ï¼Œæ˜¯æˆ‘çš„åŸåˆ™ï¼‰ğŸ§¹

å½“å‰ç”¨æˆ·è¯·æ±‚å¦‚ä¸‹ï¼š\n"""


@st.cache_data(ttl=1800)  # ç¼“å­˜30åˆ†é’Ÿ
def cached_dataframe_analysis(df_hash, query_hash, query):
    """ç¼“å­˜æ•°æ®åˆ†æç»“æœ"""
    # å®é™…çš„åˆ†æé€»è¾‘ä¼šåœ¨dataframe_agentä¸­æ‰§è¡Œ
    return None

def get_enhanced_model(model_choice="gpt-4o"):
    """è·å–å¢å¼ºçš„AIæ¨¡å‹"""
    model_configs = {
        "gpt-4o": {
            "model": "gpt-4o",
            "temperature": 0.1,
            "max_tokens": 8192
        },
        "gpt-4o-mini": {
            "model": "gpt-4o-mini", 
            "temperature": 0,
            "max_tokens": 4096
        },
        "gpt-4-turbo": {
            "model": "gpt-4-turbo-preview",
            "temperature": 0.2,
            "max_tokens": 8192
        }
    }
    
    config = model_configs.get(model_choice, model_configs["gpt-4o-mini"])
    
    return ChatOpenAI(
        base_url='https://twapi.openai-hk.com/v1',
        api_key=st.secrets['API_KEY'],
        **config
    )

def dataframe_agent(df, query, model_choice="gpt-4o", use_cache=True):
    """å¢å¼ºç‰ˆæ•°æ®åˆ†ææ™ºèƒ½ä½“"""
    
    # ç”Ÿæˆç¼“å­˜é”®
    df_hash = hash(str(df.values.tobytes()) + str(df.columns.tolist()))
    query_hash = hash(query)
    
    # å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
    if use_cache:
        try:
            cached_result = cached_dataframe_analysis(df_hash, query_hash, query)
            if cached_result:
                return cached_result
        except:
            pass
    
    # é€‰æ‹©æ¨¡å‹
    model = get_enhanced_model(model_choice)
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    try:
        agent = create_pandas_dataframe_agent(
            llm=model,
            df=df,
            verbose=True,
            allow_dangerous_code=True
        )
    except Exception as e:
        st.error(f"åˆ›å»ºæ™ºèƒ½ä½“æ—¶å‡ºé”™: {str(e)}")
        return {"answer": "æŠ±æ­‰ï¼ŒAIæ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"}

    # å¢å¼ºçš„æç¤ºè¯
    enhanced_prompt = PROMPT_TEMPLATE + f"""
    
    æ•°æ®é›†ä¿¡æ¯ï¼š
    - è¡Œæ•°ï¼š{len(df)}
    - åˆ—æ•°ï¼š{len(df.columns)}
    - åˆ—åï¼š{', '.join(df.columns.tolist())}
    - æ•°å€¼åˆ—ï¼š{', '.join(df.select_dtypes(include=['number']).columns.tolist())}
    - æ–‡æœ¬åˆ—ï¼š{', '.join(df.select_dtypes(include=['object']).columns.tolist())}
    
    ç”¨æˆ·é—®é¢˜ï¼š{query}
    
    è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„åˆ†æç»“æœã€‚
    """

    try:
        # æ‰§è¡Œåˆ†æ
        response = agent.invoke({"input": enhanced_prompt})
        result = json.loads(response["output"])
        
        # éªŒè¯ç»“æœæ ¼å¼
        if not isinstance(result, dict):
            raise ValueError("è¿”å›ç»“æœæ ¼å¼ä¸æ­£ç¡®")
            
        return result
        
    except json.JSONDecodeError as e:
        print(f"JSONè§£æé”™è¯¯: {e}")
        return {"answer": "åˆ†æç»“æœæ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°å°è¯•"}
    except Exception as err:
        print(f"åˆ†æé”™è¯¯: {err}")
        error_messages = [
            "æš‚æ—¶æ— æ³•æä¾›åˆ†æç»“æœï¼Œè¯·ç¨åé‡è¯•ï¼",
            "æ•°æ®åˆ†æé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–ç®€åŒ–é—®é¢˜",
            "AIåˆ†æè¶…æ—¶ï¼Œè¯·å°è¯•æ›´ç®€å•çš„é—®é¢˜",
            "åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚"
        ]
        import random
        return {"answer": random.choice(error_messages)}

def multi_model_analysis(df, query, models=["gpt-4o", "gpt-4o-mini"]):
    """å¤šæ¨¡å‹é›†æˆåˆ†æ"""
    results = []
    
    for model in models:
        try:
            result = dataframe_agent(df, query, model_choice=model, use_cache=False)
            results.append({"model": model, "result": result})
        except Exception as e:
            print(f"æ¨¡å‹ {model} åˆ†æå¤±è´¥: {e}")
            continue
    
    if not results:
        return {"answer": "æ‰€æœ‰æ¨¡å‹åˆ†æéƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–é—®é¢˜"}
    
    # ç®€å•çš„ç»“æœåˆå¹¶ç­–ç•¥ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›ï¼‰
    if len(results) == 1:
        return results[0]["result"]
    
    # å¦‚æœæœ‰å¤šä¸ªç»“æœï¼Œè¿”å›ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœï¼Œå¹¶æ·»åŠ å¤‡æ³¨
    primary_result = results[0]["result"]
    if "answer" in primary_result:
        primary_result["answer"] += f" (åŸºäº{len(results)}ä¸ªæ¨¡å‹çš„åˆ†æç»“æœ)"
    
    return primary_result